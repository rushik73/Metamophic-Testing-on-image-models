{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6d8b71-d55a-42ab-9b41-c9c87dff4763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c698da6e-4aec-4631-9844-ad17c988287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization values for CIFAR-10\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3f015b-dad4-4ef1-996e-c51664da8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels,\n",
    "                               kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels,\n",
    "                               kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut (projection) if shape changes (stride != 1 or channels differ)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354df633-b3b2-4a5f-8478-d046cd8ea90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet20(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, num_classes=10):\n",
    "        super(ResNet20, self).__init__()\n",
    "        self.in_channels = 16\n",
    "\n",
    "        # Initial conv: 3x3, 16 filters\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Each \"layer\" is a sequence of blocks\n",
    "        self.layer1 = self._make_layer(block, out_channels=16, blocks=3, stride=1)\n",
    "        self.layer2 = self._make_layer(block, out_channels=32, blocks=3, stride=2)\n",
    "        self.layer3 = self._make_layer(block, out_channels=64, blocks=3, stride=2)\n",
    "\n",
    "        # Global average pool and final classification layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        \"\"\"Create a stage of 'blocks' residual blocks.\"\"\"\n",
    "        strides = [stride] + [1] * (blocks - 1)  \n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb64b049-ae6f-47f3-9ced-284c1719ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24dae3f-ad5d-4754-92cc-8aae5af9b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet20().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb70ae35-b5e4-465f-bbeb-eba8526a711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations for metamorphic testing\n",
    "transformations = [\n",
    "    transforms.RandomRotation(degrees=10),  # Small rotation\n",
    "    transforms.ColorJitter(brightness=0.2),  # Slight brightness change\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))  # Small translation\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fdbe228-3050-4059-9fbe-9991cc868641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def majority_vote_prediction(model, images, transformations, device):\n",
    "    \"\"\"\n",
    "    Given a batch of images and a list of transformations,\n",
    "    compute the model's predictions on:\n",
    "        1) the original images,\n",
    "        2) each transformed version,\n",
    "    then take a majority vote across all predictions for each sample.\n",
    "    \n",
    "    Returns a tensor of shape [batch_size] with the final voted class.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # 1) Original predictions\n",
    "    with torch.no_grad():\n",
    "        original_out = model(images)\n",
    "        _, original_preds = torch.max(F.softmax(original_out, dim=1), dim=1)  # shape [batch_size]\n",
    "\n",
    "    # 2) Collect predictions in a list\n",
    "    all_preds = [original_preds]\n",
    "\n",
    "    # 3) For each metamorphic transform\n",
    "    for tf in transformations:\n",
    "        # apply transform on CPU, then move back to device\n",
    "        x_tf = tf(images.cpu()).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_tf = model(x_tf)\n",
    "            _, preds_tf = torch.max(F.softmax(out_tf, dim=1), dim=1)\n",
    "\n",
    "        all_preds.append(preds_tf)\n",
    "\n",
    "    # 4) Stack them into shape [num_transforms+1, batch_size]\n",
    "    stacked_preds = torch.stack(all_preds, dim=0)\n",
    "\n",
    "    # 5) Majority vote across the first dimension\n",
    "    voted_preds = stacked_preds.mode(dim=0).values  # shape [batch_size]\n",
    "    return voted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0809a080-44a6-4731-88d2-2d47de08dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_with_majority_vote(model, loader, transformations, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on 'loader' using majority-voted predictions (original + transforms).\n",
    "    Prints per-batch accuracy and returns the final overall accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(tqdm(loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get majority-voted predictions\n",
    "        voted_preds = majority_vote_prediction(model, images, transformations, device)\n",
    "\n",
    "        # Compare to ground-truth\n",
    "        batch_correct = (voted_preds == labels).sum().item()\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        correct += batch_correct\n",
    "        total += batch_size\n",
    "\n",
    "        # Print a line for each batch\n",
    "        print(f\"Batch {i} | MajVot Accuracy: {100.0 * batch_correct / batch_size:.2f}% | Batch Size: {batch_size}\")\n",
    "\n",
    "    # Final overall accuracy\n",
    "    overall_accuracy = 100.0 * correct / total\n",
    "    print(f\"\\nFinal MajVot Accuracy (across all test samples): {overall_accuracy:.2f}%\")\n",
    "    return overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bd845d-7537-40b0-9210-4ebbb7a2d265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                                  | 4/100 [00:00<00:06, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 1 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 2 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 3 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 4 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 5 | MajVot Accuracy: 5.00% | Batch Size: 100\n",
      "Batch 6 | MajVot Accuracy: 11.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▏                                                                          | 12/100 [00:00<00:03, 27.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7 | MajVot Accuracy: 12.00% | Batch Size: 100\n",
      "Batch 8 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 9 | MajVot Accuracy: 13.00% | Batch Size: 100\n",
      "Batch 10 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 11 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 12 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 13 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 14 | MajVot Accuracy: 13.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▋                                                                  | 22/100 [00:00<00:02, 35.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15 | MajVot Accuracy: 6.00% | Batch Size: 100\n",
      "Batch 16 | MajVot Accuracy: 10.00% | Batch Size: 100\n",
      "Batch 17 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 18 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 19 | MajVot Accuracy: 10.00% | Batch Size: 100\n",
      "Batch 20 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 21 | MajVot Accuracy: 6.00% | Batch Size: 100\n",
      "Batch 22 | MajVot Accuracy: 12.00% | Batch Size: 100\n",
      "Batch 23 | MajVot Accuracy: 13.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▏                                                         | 32/100 [00:01<00:01, 38.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 25 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 26 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 27 | MajVot Accuracy: 10.00% | Batch Size: 100\n",
      "Batch 28 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 29 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 30 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 31 | MajVot Accuracy: 12.00% | Batch Size: 100\n",
      "Batch 32 | MajVot Accuracy: 10.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████▊                                                  | 41/100 [00:01<00:01, 37.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 33 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 34 | MajVot Accuracy: 6.00% | Batch Size: 100\n",
      "Batch 35 | MajVot Accuracy: 12.00% | Batch Size: 100\n",
      "Batch 36 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 37 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 38 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 39 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 40 | MajVot Accuracy: 7.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████                                              | 46/100 [00:01<00:01, 38.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 41 | MajVot Accuracy: 6.00% | Batch Size: 100\n",
      "Batch 42 | MajVot Accuracy: 15.00% | Batch Size: 100\n",
      "Batch 43 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 44 | MajVot Accuracy: 15.00% | Batch Size: 100\n",
      "Batch 45 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 46 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 47 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 48 | MajVot Accuracy: 12.00% | Batch Size: 100\n",
      "Batch 49 | MajVot Accuracy: 10.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████████▊                                      | 55/100 [00:01<00:01, 38.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 51 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 52 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 53 | MajVot Accuracy: 12.00% | Batch Size: 100\n",
      "Batch 54 | MajVot Accuracy: 12.00% | Batch Size: 100\n",
      "Batch 55 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 56 | MajVot Accuracy: 5.00% | Batch Size: 100\n",
      "Batch 57 | MajVot Accuracy: 3.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████████▍                              | 64/100 [00:01<00:00, 39.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 58 | MajVot Accuracy: 6.00% | Batch Size: 100\n",
      "Batch 59 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 60 | MajVot Accuracy: 5.00% | Batch Size: 100\n",
      "Batch 61 | MajVot Accuracy: 13.00% | Batch Size: 100\n",
      "Batch 62 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 63 | MajVot Accuracy: 6.00% | Batch Size: 100\n",
      "Batch 64 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 65 | MajVot Accuracy: 12.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████                       | 73/100 [00:02<00:00, 38.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 66 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 67 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 68 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 69 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 70 | MajVot Accuracy: 14.00% | Batch Size: 100\n",
      "Batch 71 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 72 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 73 | MajVot Accuracy: 10.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████▌              | 83/100 [00:02<00:00, 41.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 74 | MajVot Accuracy: 10.00% | Batch Size: 100\n",
      "Batch 75 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 76 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 77 | MajVot Accuracy: 6.00% | Batch Size: 100\n",
      "Batch 78 | MajVot Accuracy: 10.00% | Batch Size: 100\n",
      "Batch 79 | MajVot Accuracy: 14.00% | Batch Size: 100\n",
      "Batch 80 | MajVot Accuracy: 16.00% | Batch Size: 100\n",
      "Batch 81 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 82 | MajVot Accuracy: 8.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████▊          | 88/100 [00:02<00:00, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 83 | MajVot Accuracy: 12.00% | Batch Size: 100\n",
      "Batch 84 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 85 | MajVot Accuracy: 11.00% | Batch Size: 100\n",
      "Batch 86 | MajVot Accuracy: 10.00% | Batch Size: 100\n",
      "Batch 87 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 88 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 89 | MajVot Accuracy: 8.00% | Batch Size: 100\n",
      "Batch 90 | MajVot Accuracy: 5.00% | Batch Size: 100\n",
      "Batch 91 | MajVot Accuracy: 12.00% | Batch Size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 92 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 93 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 94 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "Batch 95 | MajVot Accuracy: 13.00% | Batch Size: 100\n",
      "Batch 96 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 97 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 98 | MajVot Accuracy: 9.00% | Batch Size: 100\n",
      "Batch 99 | MajVot Accuracy: 7.00% | Batch Size: 100\n",
      "\n",
      "Final MajVot Accuracy (across all test samples): 9.34%\n",
      "Majority Vote final accuracy: 9.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "majvot_acc = test_with_majority_vote(model, testloader, transformations, device)\n",
    "print(f\"Majority Vote final accuracy: {majvot_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f04e4ca3-1764-4880-8f1e-86b94ff1d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, testloader, device, criterion):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # Switch off gradient tracking for validation\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # Accumulate loss * batch_size for accurate average\n",
    "            val_running_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            # Predictions\n",
    "            _, preds = torch.max(output, 1)\n",
    "            val_running_correct += (preds == target).sum().item()\n",
    "            \n",
    "            # Store for metrics\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    # Calculate average loss\n",
    "    total_samples = len(testloader.dataset)\n",
    "    val_loss = val_running_loss / total_samples\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    val_accuracy = 100.0 * val_running_correct / total_samples\n",
    "    \n",
    "    # Calculate precision, recall, F1 (weighted or macro—your choice)\n",
    "    precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "    recall    = recall_score(all_targets, all_preds, average='weighted')\n",
    "    f1        = f1_score(all_targets, all_preds, average='weighted')\n",
    "    \n",
    "    return val_loss, val_accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb9b18-b1a7-43c1-8b39-93cd1a032a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

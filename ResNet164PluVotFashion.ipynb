{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345f5476-83ec-482e-9917-2fa7e43bf82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fafd537-e004-4871-b302-9441b98ff89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization values for CIFAR-10\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eabd6da-0835-406c-ac60-149729910b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4  # Multiplicative factor for output channels in the 3rd conv\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        # 1x1 conv to reduce channels\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # 3x3 conv\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # 1x1 conv to expand channels back by expansion\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3   = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "       \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes * self.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = F.relu(self.bn2(self.conv2(out)), inplace=True)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e96a5d5-8c89-44ae-8f2f-d8ba772fe24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet164(nn.Module):\n",
    "    def __init__(self, block=Bottleneck, num_blocks=[18, 18, 18], num_classes=10):\n",
    "        super(ResNet164, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        # Initial 3x3 convolution\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, planes=16,  num_blocks=num_blocks[0], stride=1)\n",
    "        \n",
    "        self.layer2 = self._make_layer(block, planes=32,  num_blocks=num_blocks[1], stride=2)\n",
    "        \n",
    "        self.layer3 = self._make_layer(block, planes=64,  num_blocks=num_blocks[2], stride=2)\n",
    "        \n",
    "        self.linear = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "\n",
    "       \n",
    "        out = F.avg_pool2d(out, out.size(3))  # or out.shape[2]\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16399a6f-5028-4c7f-8d6c-799fbb979591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / total\n",
    "    test_acc = 100.0 * correct / total\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08651259-b2cc-4442-8ef7-249643e97a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet164().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1, momentum=0.9, weight_decay=1e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a8d418-c84c-40b4-b6cb-f3f5afffb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations for metamorphic testing\n",
    "transformations = [\n",
    "    transforms.RandomRotation(degrees=10),  # Small rotation\n",
    "    transforms.ColorJitter(brightness=0.2),  # Slight brightness change\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))  # Small translation\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f98b16e7-b718-4189-81c8-27f7088484cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def plurality_vote_prediction(model, images, transformations, device):\n",
    "    \"\"\"\n",
    "    Given a batch of images and a list of transformations,\n",
    "    compute:\n",
    "    The original prediction f(x)\n",
    "    The predictions for each transformed image f(T_i(x))\n",
    "    Then, determine the mode (most frequent prediction) among the transformed predictions.\n",
    "    If f(x) equals the mode, the prediction is accepted; otherwise, it is rejected.\n",
    "    \n",
    "    Returns:\n",
    "      accepted_preds: a tensor of shape [batch_size] where accepted samples have their original prediction,\n",
    "                      and rejected samples are marked with -1.\n",
    "      accepted_mask: a boolean tensor of shape [batch_size] indicating which samples were accepted.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 1) Original predictions\n",
    "    with torch.no_grad():\n",
    "        original_out = model(images)\n",
    "        _, original_preds = torch.max(F.softmax(original_out, dim=1), dim=1)  # shape [batch_size]\n",
    "    \n",
    "    # 2) Get predictions from each transformation (set S)\n",
    "    transformed_preds_list = []\n",
    "    for tf in transformations:\n",
    "        # Apply the transformation on CPU (if required) and move back to device.\n",
    "        x_tf = tf(images.cpu()).to(device)\n",
    "        with torch.no_grad():\n",
    "            out_tf = model(x_tf)\n",
    "            _, preds_tf = torch.max(F.softmax(out_tf, dim=1), dim=1)\n",
    "        transformed_preds_list.append(preds_tf)\n",
    "    \n",
    "    # 3) Compute the mode (most frequent prediction) over the transformed predictions.\n",
    "    #    Note: If there are no transformations, we simply use the original predictions.\n",
    "    if len(transformed_preds_list) > 0:\n",
    "        stacked_preds = torch.stack(transformed_preds_list, dim=0)  # shape: [num_transforms, batch_size]\n",
    "        mode_preds = stacked_preds.mode(dim=0).values  # shape: [batch_size]\n",
    "    else:\n",
    "        mode_preds = original_preds\n",
    "    \n",
    "    # 4) Determine acceptance: accepted if original_preds equals mode_preds.\n",
    "    accepted_mask = (original_preds == mode_preds)\n",
    "    \n",
    "    # 5) Create an output: for accepted samples, return original prediction; for rejected, set to -1.\n",
    "    accepted_preds = original_preds.clone()\n",
    "    accepted_preds[~accepted_mask] = -1\n",
    "    \n",
    "    return accepted_preds, accepted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88edcf99-50fb-4ad4-9921-f52e212806d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_with_plurality_vote(model, loader, transformations, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on 'loader' using PluVot:\n",
    "      - For each batch, it computes the plurality-voted predictions.\n",
    "      - A sample is accepted if the original prediction f(x) equals the mode of the transformed predictions.\n",
    "      - Rejected samples are marked with -1.\n",
    "    \n",
    "    It prints per-batch acceptance counts and returns:\n",
    "      - The accuracy among accepted samples.\n",
    "      - The overall acceptance rate.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    total_accepted = 0\n",
    "    correct_accepted = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(tqdm(loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Get PluVot predictions and acceptance mask for the batch.\n",
    "        accepted_preds, accepted_mask = plurality_vote_prediction(model, images, transformations, device)\n",
    "        \n",
    "        batch_size = labels.size(0)\n",
    "        total_samples += batch_size\n",
    "        batch_accepted = accepted_mask.sum().item()\n",
    "        total_accepted += batch_accepted\n",
    "        \n",
    "        # Calculate accuracy among accepted samples\n",
    "        if batch_accepted > 0:\n",
    "            batch_correct = (accepted_preds[accepted_mask] == labels[accepted_mask]).sum().item()\n",
    "            correct_accepted += batch_correct\n",
    "        \n",
    "        print(f\"Batch {i} | Accepted: {batch_accepted}/{batch_size}\")\n",
    "    \n",
    "    overall_acceptance_rate = 100.0 * total_accepted / total_samples\n",
    "    accepted_accuracy = 100.0 * correct_accepted / total_accepted if total_accepted > 0 else 0.0\n",
    "    \n",
    "    print(f\"\\nOverall Acceptance Rate: {overall_acceptance_rate:.2f}%\")\n",
    "    print(f\"Accuracy among Accepted Samples: {accepted_accuracy:.2f}%\")\n",
    "    \n",
    "    return accepted_accuracy, overall_acceptance_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e42807-538a-4064-be38-3d497758d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                    | 2/100 [00:01<01:10,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 | Accepted: 100/100\n",
      "Batch 1 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                                  | 4/100 [00:01<00:32,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 | Accepted: 100/100\n",
      "Batch 3 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▏                                                                                | 6/100 [00:02<00:22,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 | Accepted: 100/100\n",
      "Batch 5 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▉                                                                               | 8/100 [00:02<00:17,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 | Accepted: 100/100\n",
      "Batch 7 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                            | 10/100 [00:02<00:15,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8 | Accepted: 100/100\n",
      "Batch 9 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▏                                                                          | 12/100 [00:03<00:14,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10 | Accepted: 100/100\n",
      "Batch 11 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▉                                                                         | 14/100 [00:03<00:13,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12 | Accepted: 100/100\n",
      "Batch 13 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▌                                                                       | 16/100 [00:03<00:13,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14 | Accepted: 100/100\n",
      "Batch 15 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▎                                                                     | 18/100 [00:04<00:12,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16 | Accepted: 100/100\n",
      "Batch 17 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████                                                                    | 20/100 [00:04<00:12,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18 | Accepted: 100/100\n",
      "Batch 19 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▋                                                                  | 22/100 [00:04<00:12,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20 | Accepted: 100/100\n",
      "Batch 21 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▍                                                                | 24/100 [00:05<00:11,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22 | Accepted: 100/100\n",
      "Batch 23 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████                                                               | 26/100 [00:05<00:11,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24 | Accepted: 100/100\n",
      "Batch 25 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████▊                                                             | 28/100 [00:05<00:11,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26 | Accepted: 100/100\n",
      "Batch 27 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▌                                                           | 30/100 [00:06<00:10,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 28 | Accepted: 100/100\n",
      "Batch 29 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▏                                                         | 32/100 [00:06<00:10,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30 | Accepted: 100/100\n",
      "Batch 31 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████▉                                                        | 34/100 [00:06<00:10,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32 | Accepted: 100/100\n",
      "Batch 33 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▌                                                      | 36/100 [00:06<00:09,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34 | Accepted: 100/100\n",
      "Batch 35 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▎                                                    | 38/100 [00:07<00:09,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36 | Accepted: 100/100\n",
      "Batch 37 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████                                                   | 40/100 [00:07<00:09,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38 | Accepted: 100/100\n",
      "Batch 39 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████▋                                                 | 42/100 [00:07<00:08,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40 | Accepted: 100/100\n",
      "Batch 41 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▍                                               | 44/100 [00:08<00:08,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 42 | Accepted: 100/100\n",
      "Batch 43 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████                                              | 46/100 [00:08<00:08,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 44 | Accepted: 100/100\n",
      "Batch 45 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████▊                                            | 48/100 [00:08<00:07,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 46 | Accepted: 100/100\n",
      "Batch 47 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▌                                          | 50/100 [00:09<00:07,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 48 | Accepted: 100/100\n",
      "Batch 49 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████▏                                        | 52/100 [00:09<00:07,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 | Accepted: 100/100\n",
      "Batch 51 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████████▉                                       | 54/100 [00:09<00:07,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 52 | Accepted: 100/100\n",
      "Batch 53 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████████▌                                     | 56/100 [00:10<00:06,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 54 | Accepted: 100/100\n",
      "Batch 55 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████▎                                   | 58/100 [00:10<00:06,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 56 | Accepted: 100/100\n",
      "Batch 57 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████                                  | 60/100 [00:10<00:06,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 58 | Accepted: 100/100\n",
      "Batch 59 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████████▋                                | 62/100 [00:10<00:05,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60 | Accepted: 100/100\n",
      "Batch 61 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████████▍                              | 64/100 [00:11<00:05,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 62 | Accepted: 100/100\n",
      "Batch 63 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████                             | 66/100 [00:11<00:05,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64 | Accepted: 100/100\n",
      "Batch 65 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████████▊                           | 68/100 [00:11<00:04,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 66 | Accepted: 100/100\n",
      "Batch 67 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████▍                         | 70/100 [00:12<00:04,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 68 | Accepted: 100/100\n",
      "Batch 69 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████▏                       | 72/100 [00:12<00:04,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 70 | Accepted: 100/100\n",
      "Batch 71 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████████████████████████████████▉                      | 74/100 [00:12<00:03,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 72 | Accepted: 100/100\n",
      "Batch 73 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████████▌                    | 76/100 [00:13<00:03,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 74 | Accepted: 100/100\n",
      "Batch 75 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████████▎                  | 78/100 [00:13<00:03,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 76 | Accepted: 100/100\n",
      "Batch 77 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████                 | 80/100 [00:13<00:03,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 78 | Accepted: 100/100\n",
      "Batch 79 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████▋               | 82/100 [00:14<00:02,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 80 | Accepted: 100/100\n",
      "Batch 81 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████▍             | 84/100 [00:14<00:02,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 82 | Accepted: 100/100\n",
      "Batch 83 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████            | 86/100 [00:14<00:02,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 84 | Accepted: 100/100\n",
      "Batch 85 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████▊          | 88/100 [00:14<00:01,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 86 | Accepted: 100/100\n",
      "Batch 87 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████▌        | 90/100 [00:15<00:01,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 88 | Accepted: 100/100\n",
      "Batch 89 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████▏      | 92/100 [00:15<00:01,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 90 | Accepted: 100/100\n",
      "Batch 91 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████████▉     | 94/100 [00:15<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 92 | Accepted: 100/100\n",
      "Batch 93 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████████▌   | 96/100 [00:16<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 94 | Accepted: 100/100\n",
      "Batch 95 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████████▎ | 98/100 [00:16<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 96 | Accepted: 100/100\n",
      "Batch 97 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 98 | Accepted: 100/100\n",
      "Batch 99 | Accepted: 100/100\n",
      "\n",
      "Overall Acceptance Rate: 99.99%\n",
      "Accuracy among Accepted Samples: 10.00%\n",
      "Plurality Vote Accuracy among accepted samples: 10.00%\n",
      "Overall Acceptance Rate: 99.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accepted_acc, acceptance_rate = test_with_plurality_vote(model, testloader, transformations, device)\n",
    "print(f\"Plurality Vote Accuracy among accepted samples: {accepted_acc:.2f}%\")\n",
    "print(f\"Overall Acceptance Rate: {acceptance_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2b89d-5fbb-4701-a75b-01e0b9060d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

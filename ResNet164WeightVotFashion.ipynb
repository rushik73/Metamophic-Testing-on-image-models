{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97251755-2f8e-4cd6-98f7-d4eeecf2d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc35857-1cea-4afa-a3ad-03c32165ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization values for CIFAR-10\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af473fe-0b6e-4fb7-99e4-5d01385f0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4  # Multiplicative factor for output channels in the 3rd conv\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        # 1x1 conv to reduce channels\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # 3x3 conv\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # 1x1 conv to expand channels back by expansion\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3   = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "       \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes * self.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = F.relu(self.bn2(self.conv2(out)), inplace=True)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1a92ad-9aaf-4d4a-9c7c-97ae62c70015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet164(nn.Module):\n",
    "    def __init__(self, block=Bottleneck, num_blocks=[18, 18, 18], num_classes=10):\n",
    "        super(ResNet164, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        # Initial 3x3 convolution\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, planes=16,  num_blocks=num_blocks[0], stride=1)\n",
    "        \n",
    "        self.layer2 = self._make_layer(block, planes=32,  num_blocks=num_blocks[1], stride=2)\n",
    "        \n",
    "        self.layer3 = self._make_layer(block, planes=64,  num_blocks=num_blocks[2], stride=2)\n",
    "        \n",
    "        self.linear = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "\n",
    "       \n",
    "        out = F.avg_pool2d(out, out.size(3))  # or out.shape[2]\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c558144-8515-4fd9-92e3-99babd227c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / total\n",
    "    test_acc = 100.0 * correct / total\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659c33cd-a531-4f4c-b545-d8da96a22730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet164().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1, momentum=0.9, weight_decay=1e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dcb48ae-256c-44b8-bb03-2c3b630d8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations for metamorphic testing\n",
    "transformations = [\n",
    "    transforms.RandomRotation(degrees=10),  # Small rotation\n",
    "    transforms.ColorJitter(brightness=0.2),  # Slight brightness change\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))  # Small translation\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68b3d65-e9a6-46d3-93ae-6c0b84dd4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weighted_vote_prediction(model, images, transformations, weights, device, num_classes=10):\n",
    "    \"\"\"\n",
    "      weighted_preds: Tensor of shape [batch_size] with the weighted vote result.\n",
    "      accepted_mask: Boolean tensor of shape [batch_size] indicating accepted samples.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # 1) Original predictions\n",
    "    with torch.no_grad():\n",
    "        original_out = model(images)\n",
    "        _, original_preds = torch.max(F.softmax(original_out, dim=1), dim=1)  # shape: [batch_size]\n",
    "\n",
    "    # Initialize weighted vote sum using one-hot encoding of original predictions and its weight.\n",
    "    weighted_sum = F.one_hot(original_preds, num_classes=num_classes).float() * weights[0]\n",
    "\n",
    "    # 2) For each metamorphic transformation, get predictions and add weighted one-hot votes.\n",
    "    for i, tf in enumerate(transformations):\n",
    "        # Apply transformation on CPU and then move to device.\n",
    "        x_tf = tf(images.cpu()).to(device)\n",
    "        with torch.no_grad():\n",
    "            out_tf = model(x_tf)\n",
    "            _, preds_tf = torch.max(F.softmax(out_tf, dim=1), dim=1)\n",
    "        # Convert predictions to one-hot and multiply by weight.\n",
    "        weighted_sum += F.one_hot(preds_tf, num_classes=num_classes).float() * weights[i+1]\n",
    "\n",
    "    # 3) Final weighted vote: for each sample, take the argmax of the weighted sum.\n",
    "    weighted_preds = weighted_sum.argmax(dim=1)  # shape: [batch_size]\n",
    "\n",
    "    # 4) Determine acceptance: accept if weighted vote equals the original prediction.\n",
    "    accepted_mask = (weighted_preds == original_preds)\n",
    "\n",
    "    return weighted_preds, accepted_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "932547a7-988d-41fc-8207-73ae8a7c9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_with_weighted_vote(model, loader, transformations, weights, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set 'loader' using weighted voting.\n",
    "    For each batch:\n",
    "      - Computes weighted vote predictions (using original + transformed outputs).\n",
    "      - Accepts a sample only if the weighted vote equals the original prediction.\n",
    "    \n",
    "    Prints per-batch information and returns:\n",
    "      - The accuracy among accepted samples.\n",
    "      - The overall acceptance rate.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    total_accepted = 0\n",
    "    correct_accepted = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(tqdm(loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get weighted vote predictions and acceptance mask for the batch.\n",
    "        weighted_preds, accepted_mask = weighted_vote_prediction(model, images, transformations, weights, device)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        total_samples += batch_size\n",
    "        batch_accepted = accepted_mask.sum().item()\n",
    "        total_accepted += batch_accepted\n",
    "\n",
    "        # Compute correct predictions among accepted samples.\n",
    "        if batch_accepted > 0:\n",
    "            batch_correct = (weighted_preds[accepted_mask] == labels[accepted_mask]).sum().item()\n",
    "            correct_accepted += batch_correct\n",
    "\n",
    "        print(f\"Batch {i} | Accepted: {batch_accepted}/{batch_size}\")\n",
    "\n",
    "    overall_acceptance_rate = 100.0 * total_accepted / total_samples\n",
    "    accepted_accuracy = 100.0 * correct_accepted / total_accepted if total_accepted > 0 else 0.0\n",
    "\n",
    "    print(f\"\\nOverall Acceptance Rate: {overall_acceptance_rate:.2f}%\")\n",
    "    print(f\"Accuracy among Accepted Samples: {accepted_accuracy:.2f}%\")\n",
    "    \n",
    "    return accepted_accuracy, overall_acceptance_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f31c97-9254-41e6-b722-a0badd3c5477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                    | 2/100 [00:01<00:50,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 | Accepted: 96/100\n",
      "Batch 1 | Accepted: 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                                  | 4/100 [00:01<00:26,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 | Accepted: 95/100\n",
      "Batch 3 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▏                                                                                | 6/100 [00:01<00:19,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 | Accepted: 100/100\n",
      "Batch 5 | Accepted: 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▉                                                                               | 8/100 [00:02<00:16,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 | Accepted: 95/100\n",
      "Batch 7 | Accepted: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                            | 10/100 [00:02<00:15,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8 | Accepted: 99/100\n",
      "Batch 9 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▏                                                                          | 12/100 [00:02<00:14,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10 | Accepted: 100/100\n",
      "Batch 11 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▉                                                                         | 14/100 [00:03<00:13,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12 | Accepted: 95/100\n",
      "Batch 13 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▌                                                                       | 16/100 [00:03<00:13,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14 | Accepted: 100/100\n",
      "Batch 15 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▎                                                                     | 18/100 [00:03<00:13,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16 | Accepted: 99/100\n",
      "Batch 17 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████                                                                    | 20/100 [00:04<00:12,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18 | Accepted: 100/100\n",
      "Batch 19 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▋                                                                  | 22/100 [00:04<00:12,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20 | Accepted: 100/100\n",
      "Batch 21 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▍                                                                | 24/100 [00:04<00:11,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22 | Accepted: 97/100\n",
      "Batch 23 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████                                                               | 26/100 [00:04<00:11,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24 | Accepted: 100/100\n",
      "Batch 25 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████▊                                                             | 28/100 [00:05<00:11,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26 | Accepted: 100/100\n",
      "Batch 27 | Accepted: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▌                                                           | 30/100 [00:05<00:10,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 28 | Accepted: 97/100\n",
      "Batch 29 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▏                                                         | 32/100 [00:05<00:10,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30 | Accepted: 100/100\n",
      "Batch 31 | Accepted: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████▉                                                        | 34/100 [00:06<00:10,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32 | Accepted: 99/100\n",
      "Batch 33 | Accepted: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▌                                                      | 36/100 [00:06<00:10,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34 | Accepted: 97/100\n",
      "Batch 35 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▎                                                    | 38/100 [00:06<00:09,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36 | Accepted: 100/100\n",
      "Batch 37 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████                                                   | 40/100 [00:07<00:09,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38 | Accepted: 100/100\n",
      "Batch 39 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████▋                                                 | 42/100 [00:07<00:09,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40 | Accepted: 98/100\n",
      "Batch 41 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▍                                               | 44/100 [00:07<00:08,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 42 | Accepted: 98/100\n",
      "Batch 43 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████                                              | 46/100 [00:08<00:08,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 44 | Accepted: 100/100\n",
      "Batch 45 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████▊                                            | 48/100 [00:08<00:08,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 46 | Accepted: 97/100\n",
      "Batch 47 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▌                                          | 50/100 [00:08<00:07,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 48 | Accepted: 98/100\n",
      "Batch 49 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████▏                                        | 52/100 [00:09<00:07,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 | Accepted: 99/100\n",
      "Batch 51 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████████▉                                       | 54/100 [00:09<00:07,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 52 | Accepted: 97/100\n",
      "Batch 53 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████████▌                                     | 56/100 [00:09<00:06,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 54 | Accepted: 99/100\n",
      "Batch 55 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████▎                                   | 58/100 [00:09<00:06,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 56 | Accepted: 98/100\n",
      "Batch 57 | Accepted: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████                                  | 60/100 [00:10<00:06,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 58 | Accepted: 96/100\n",
      "Batch 59 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████████▋                                | 62/100 [00:10<00:05,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60 | Accepted: 100/100\n",
      "Batch 61 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████████▍                              | 64/100 [00:10<00:05,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 62 | Accepted: 98/100\n",
      "Batch 63 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████                             | 66/100 [00:11<00:05,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64 | Accepted: 99/100\n",
      "Batch 65 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████████▊                           | 68/100 [00:11<00:04,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 66 | Accepted: 97/100\n",
      "Batch 67 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████▍                         | 70/100 [00:11<00:04,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 68 | Accepted: 100/100\n",
      "Batch 69 | Accepted: 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████▏                       | 72/100 [00:12<00:04,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 70 | Accepted: 100/100\n",
      "Batch 71 | Accepted: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████████████████████████████████▉                      | 74/100 [00:12<00:03,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 72 | Accepted: 99/100\n",
      "Batch 73 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████████▌                    | 76/100 [00:12<00:03,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 74 | Accepted: 95/100\n",
      "Batch 75 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████████▎                  | 78/100 [00:13<00:03,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 76 | Accepted: 98/100\n",
      "Batch 77 | Accepted: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████                 | 80/100 [00:13<00:03,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 78 | Accepted: 100/100\n",
      "Batch 79 | Accepted: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████▋               | 82/100 [00:13<00:02,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 80 | Accepted: 98/100\n",
      "Batch 81 | Accepted: 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████▍             | 84/100 [00:13<00:02,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 82 | Accepted: 99/100\n",
      "Batch 83 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████            | 86/100 [00:14<00:02,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 84 | Accepted: 99/100\n",
      "Batch 85 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████▊          | 88/100 [00:14<00:01,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 86 | Accepted: 97/100\n",
      "Batch 87 | Accepted: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████▌        | 90/100 [00:14<00:01,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 88 | Accepted: 98/100\n",
      "Batch 89 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████▏      | 92/100 [00:15<00:01,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 90 | Accepted: 97/100\n",
      "Batch 91 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████████▉     | 94/100 [00:15<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 92 | Accepted: 99/100\n",
      "Batch 93 | Accepted: 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████████▌   | 96/100 [00:15<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 94 | Accepted: 96/100\n",
      "Batch 95 | Accepted: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████████▎ | 98/100 [00:16<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 96 | Accepted: 98/100\n",
      "Batch 97 | Accepted: 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 98 | Accepted: 100/100\n",
      "Batch 99 | Accepted: 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acceptance Rate: 98.33%\n",
      "Accuracy among Accepted Samples: 10.10%\n",
      "Weighted Vote Accuracy among accepted samples: 10.10%\n",
      "Overall Acceptance Rate: 98.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weights = [0.5, 0.25, 0.25, 0.25]\n",
    "\n",
    "acc_weighted, acceptance_rate = test_with_weighted_vote(model, testloader, transformations, weights, device)\n",
    "print(f\"Weighted Vote Accuracy among accepted samples: {acc_weighted:.2f}%\")\n",
    "print(f\"Overall Acceptance Rate: {acceptance_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6ca7e-c82c-425e-9959-bfbad9783d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
